<!DOCTYPE html>
<html>
<head>
    <!-- Meta session. Remove if don't use Bootstrap -->
    <meta charset="utf-8">
    <link href="data:image/x-icon;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQEAYAAABPYyMiAAAABmJLR0T///////8JWPfcAAAACXBIWXMAAABIAAAASABGyWs+AAACbUlEQVRIx7WUsU/qUBTGv96WSlWeEBZijJggxrREdwYixMnByYEyOvgfsBAMG0xuDsZ/QGc3NDFhgTioiYsmkhBYGLSBkLYR0va8gSjvQXiIT7/l5ibfOd/v3pN7gSmVSMTj8ThRfzdYk8lkMpl83/+AVFVVVXU0eHiVJEmSpB8DIcpkMplsdhCYz+fzhQJROBwOh8PDQN+oQCAQCASIRFEURZHI45GkP0/e7Xa73e70AMJnjel0Op1OA6oaDB4eAkAw6PcDvZ5t6zrw/Hx2trAw/cHYZ426ruu6DtzcGEYuBzQa19etFvD4WKtls4AoRqMPDwBjjLGPrt84ilgsFovF6EOapmmaRiP6O/jbAIguL4vFYpHGqlKpVCoVomq1Wq1Wibxer9fn+w+Q9+cUiUQikQhNrfdgWZZlWf4yyGhj27Zt254MUK/X6/X6F0aiKIqiKIOCYRmGYRjGZADLsizLIgqFQqHV1SkAnp5OTn79ItK0qyuPZ7SxaZqmaU4GKJfPzxmbfAPc/f3pqaIQLS8vLtZqgOP0bYyJoiAARC5Xrwf4/Vtbb2+Th1YqlUqlErC01GgkEkCz2WxyHLC+LsuiCAiCJLlcgM+3vd3pcBzXaJTLR0dEs7Ptdv+D4TiOG/A6DsBxQKvV621sAGtru7vl8ngAjuvXv7xcXIgiwNjMjCj2h+k4fQfPA4LA8xwHCO323V2hABiG223bwPy8xwMAbvfcHGMAY32j47y+3t4OAsZpZ2dzEwAsy7IcBxAExhwHMIxOx3GAlZVUyjT/1WFIudzenstFlEpFo9M8o+Pj/X2eJzo4SCR4fnzdb2N4Pyv9cduVAAAAAElFTkSuQmCC" rel="icon" type="image/x-icon" />
    <title> Definitely Not Aura RGB </title>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/socket.io/2.1.1/socket.io.slim.js"></script>
    <style>

        body {
            background: black;
            font: 24px "Lucida Grande", Helvetica, Arial, sans-serif;
            color: white;
        }

        #init_btn {
            display: flex;
            justify-content: center;
            align-items: center;
            position: absolute;
            top: 0;
            right: 0;
            bottom: 0;
            left: 0;
            text-align: center;
            vertical-align: middle;
            flex-direction: column;
        }
    </style>
</head>
<body>
    <div id="init_btn">
        <h1 onclick="main2({})" style="background:#222"> Click to start </h1>

        <h1 onclick="main2({ noDrawing: true })" style="background:#222"> Click to start (No animation) </h1>
    </div>
    <script>
        'use strict';

        //http://scienceprimer.com/javascript-code-convert-light-wavelength-color
        // takes wavelength in nm and returns an rgba value
        const wavelengthToColor = (wavelength) => {
            var R,
                G,
                B,
                alpha,
                colorSpace,
                wl = wavelength,
                gamma = 1;


            if (wl >= 380 && wl < 440) {
                R = -1 * (wl - 440) / (440 - 380);
                G = 0;
                B = 1;
            } else if (wl >= 440 && wl < 490) {
                R = 0;
                G = (wl - 440) / (490 - 440);
                B = 1;
            } else if (wl >= 490 && wl < 510) {
                R = 0;
                G = 1;
                B = -1 * (wl - 510) / (510 - 490);
            } else if (wl >= 510 && wl < 580) {
                R = (wl - 510) / (580 - 510);
                G = 1;
                B = 0;
            } else if (wl >= 580 && wl < 645) {
                R = 1;
                G = -1 * (wl - 645) / (645 - 580);
                B = 0.0;
            } else if (wl >= 645 && wl <= 780) {
                R = 1;
                G = 0;
                B = 0;
            } else {
                R = 0;
                G = 0;
                B = 0;
            }

            // intensty is lower at the edges of the visible spectrum.
            if (wl > 780 || wl < 380) {
                alpha = 0;
            } else if (wl > 700) {
                alpha = (780 - wl) / (780 - 700);
            } else if (wl < 420) {
                alpha = (wl - 380) / (420 - 380);
            } else {
                alpha = 1;
            }

            colorSpace = ["rgba(" + (R * 100) + "%," + (G * 100) + "%," + (B * 100) + "%, " + alpha + ")", R, G, B, alpha]

            // colorSpace is an array with 5 elements.
            // The first element is the complete code as a string.
            // Use colorSpace[0] as is to display the desired color.
            // use the last four elements alone or together to access each of the individual r, g, b and a channels.

            return colorSpace;
        }


        const MIN_SAMPLES = 0;  // will be initialized when AudioContext is created.
        const GOOD_ENOUGH_CORRELATION = 0.5; // this is the "bar" for how close a correlation needs to be

        function autoCorrelate(buf, sampleRate) {
            const SIZE = buf.length;
            const MAX_SAMPLES = Math.floor(SIZE / 2);
            //console.log(MAX_SAMPLES);

            let best_offset = -1;
            let best_correlation = 0;
            let rms = 0;
            let foundGoodCorrelation = false;
            let correlations = new Array(MAX_SAMPLES);

            for (var i = 0; i < SIZE; i++) {
                var val = buf[i];
                rms += val * val;
            }
            rms = Math.sqrt(rms / SIZE);
            //g_result.rms = rms;
            //console.log(rms);
            if (rms < 0.01) // not enough signal
                return { freq: -1, vol: rms };

            var lastCorrelation = 1;

            //console.log({MIN_SAMPLES,MAX_SAMPLES});

            for (var offset = MIN_SAMPLES; offset < MAX_SAMPLES; offset++) {
                var correlation = 0;

                for (var i = 0; i < MAX_SAMPLES; i++) {
                    correlation += Math.abs((buf[i]) - (buf[i + offset]));
                }

                //console.log(correlation);

                correlation = 1 - (correlation / MAX_SAMPLES);
                correlations[offset] = correlation; // store it, for the tweaking we need to do below.
                if ((correlation > GOOD_ENOUGH_CORRELATION) && (correlation > lastCorrelation)) {
                    foundGoodCorrelation = true;
                    if (correlation > best_correlation) {
                        best_correlation = correlation;
                        best_offset = offset;
                    }
                } else if (foundGoodCorrelation) {
                    // short-circuit - we found a good correlation, then a bad one, so we'd just be seeing copies from here.
                    // Now we need to tweak the offset - by interpolating between the values to the left and right of the
                    // best offset, and shifting it a bit.  This is complex, and HACKY in this code (happy to take PRs!) -
                    // we need to do a curve fit on correlations[] around best_offset in order to better determine precise
                    // (anti-aliased) offset.

                    // we know best_offset >=1,
                    // since foundGoodCorrelation cannot go to true until the second pass (offset=1), and
                    // we can't drop into this clause until the following pass (else if).

                    var shift = (correlations[best_offset + 1] - correlations[best_offset - 1]) / correlations[best_offset];
                    //console.log(correlation);
                    return { freq: (sampleRate / (best_offset + (8 * shift))), vol: rms };
                }
                lastCorrelation = correlation;
            }

            //When it's the very first band.
            if (best_correlation > 0.01) {
                return { freq: (sampleRate / best_offset), vol: rms };
            }

            //console.log("f = " + sampleRate/best_offset + "Hz (rms: " + rms + " confidence: " + best_correlation + ")")
            return { freq: -1, vol: rms };
            //	var best_frequency = sampleRate/best_offset;
        }

        const ws_server = 'http://localhost:9997';

        const main = (ms_input) => {
            let socket = null;
            try {
                if (window.location.origin != "file://") {
                    socket = io(ws_server);
                } else {
                    console.log("Started as standalone webpage. WebSocket and AudioWorklet will not start.");
                }
            } catch (e) {
                console.log(e);
            }

            let audioapi = window.AudioContext || window.webkitAudioContext;
            let audioCtx = new audioapi();

            //Create audio source
            //Here, we use an audio file, but this could also be e.g. microphone input
            let audioEle = null;

            try {
                audioEle = new Audio();
                //audioEle.src = "test.flac";
                audioEle.src = 'my-audio.mp3';
                //audioEle.src = '880.wav';//insert file name here
                audioEle.autoplay = !ms_input; //true;
                audioEle.preload = 'auto';
            } catch (e) {
                console.log(e);
            }

            const audioSourceNode = ms_input ?
                audioCtx.createMediaStreamSource(ms_input) : audioEle ? audioCtx.createMediaElementSource(audioEle) : null;
            if (!audioSourceNode) { console.log("No Audio source found."); return; }

            //Create filter
            const biquadFilter = audioCtx.createBiquadFilter();
            biquadFilter.type = "lowshelf";
            biquadFilter.frequency.setValueAtTime(400, audioCtx.currentTime);
            biquadFilter.gain.setValueAtTime(0, audioCtx.currentTime);

            //Create analyser node
            const analyserNode = audioCtx.createAnalyser();
            analyserNode.fftSize = 8192; //[32, 32768]
            analyserNode.minDecibels = -200; //As low as -140
            analyserNode.maxDecibels = -5;
            analyserNode.smoothingTimeConstant = 0.72;
            const bufferLength = analyserNode.frequencyBinCount;
            let dataArray = new Float32Array(bufferLength);
            const anotherbufferlength = analyserNode.fftSize;
            let AnothrDataArray = new Float32Array(anotherbufferlength);

            //Create Process node (It is not working. onaudioprocess never called.)
            //let scriptNode = audioCtx.createScriptProcessor(1024, 1, 1);

            //scriptNode.onaudioprocess = function (audioProcessingEvent) {
            //	g_result.fps_a++;
            //    console.log("o");
            //};

            //console.log(analyserNode);

            //https://developers.google.com/web/updates/2017/12/audio-worklet
            //https://googlechromelabs.github.io/web-audio-samples/audio-worklet/
            let foundWorklet = audioCtx.audioWorklet;

            if (socket && foundWorklet) {
                console.log("Found audioWorklet! No more force showing Canvas!");

                audioCtx.audioWorklet.addModule('processor.js', { credentials: "include" }).then(() => {
                    let AWNode = new AudioWorkletNode(audioCtx, 'my-worklet-processor');

                    let aw_lock = false;
                    const max_poll_freq = 144;


                    AWNode.port.onmessage = (event) => {
                        // Handling data from the processor.
                        //console.log(event);
                        if (aw_lock) { console.log("locked"); return; }
                        aw_lock = true;

                        if (socket && Math.random() < max_poll_freq / g_result.last_fps_a) {
                            analyserNode.getFloatFrequencyData(dataArray);
                            analyserNode.getFloatTimeDomainData(AnothrDataArray);
                            start_analysis_frame();

                            socket.emit("aura", [led_r, led_g, led_b]);
                            socket.emit("logi", [sce_r, sce_g, sce_b].map(d => Math.round(d / 256 * 100)));
                        }
                        g_result.fps_a++;
                        aw_lock = false;
                    };

                    AWNode.port.postMessage('Hello!');
                    console.log(AWNode);

                    audioSourceNode.connect(biquadFilter);
                    biquadFilter.connect(AWNode);
                    AWNode.connect(analyserNode);
                    if (!ms_input) {
                        //audioSourceNode.connect(scriptNode);
                        analyserNode.connect(audioCtx.destination);
                    }
                }).catch((e) => {
                    foundWorklet = false;
                    //No suprise. Just connect nodes.

                    //Set up audio node network
                    audioSourceNode.connect(biquadFilter);
                    biquadFilter.connect(analyserNode);
                    if (!ms_input) {
                        //audioSourceNode.connect(scriptNode);
                        analyserNode.connect(audioCtx.destination);
                    }

                    if (e.toString().includes("AbortError")) {
                        console.log("audioWorklet requires a server actually hosting them!");
                    } else {
                        console.log(e);
                    }
                });
            } else {
                //No suprise. Just connect nodes.

                //Set up audio node network
                audioSourceNode.connect(biquadFilter);
                biquadFilter.connect(analyserNode);
                if (!ms_input) {
                    //audioSourceNode.connect(scriptNode);
                    analyserNode.connect(audioCtx.destination);
                }
                //audioSourceNode.connect(analyserNode);
                //analyserNode.connect(audioCtx.destination);

                //console.log(audioCtx.sampleRate);
            }

            let led_r, led_g, led_b, sce_r, sce_g, sce_b;

            //Create 2D canvas
            const canvas = document.createElement('canvas');
            canvas.style.position = 'absolute';
            canvas.style.top = 0;
            canvas.style.left = 0;
            canvas.width = window.innerWidth;
            canvas.height = window.innerHeight;
            document.body.appendChild(canvas);
            const canvasCtx = canvas.getContext('2d');
            canvasCtx.clearRect(0, 0, canvas.width, canvas.height);

            const spectrum_base = 440; //Hz
            const audible_range = [20, 20000];
            const sampleRate = audioCtx.sampleRate; //Hz (By observe)
            console.log({ sampleRate: sampleRate });

            //TODO: Someone provide me a perfect formula? This table would be very clumsy...
            const sum_width = () => {
                const sum_map = {
                    44100: {
                        1024: 2.026,
                        //32768: 1038.9999999999984
                    },
                    48000: {
                        1024: 2.2027,
                        2048: 4.811886212799751,
                        4096: 10.436921905773833,
                        8192: 22.500285974836988,
                        16384: 48.253599492306485,
                        32768: 103.01339729248795
                    },
                    192000: {
                        1024: 0.5506728826337318, //375Hz, 60+FPS
                        2048: 1.2029715531999376, //187.6832844Hz, 60+FPS
                        4096: 2.6092304764434577, //93.7957987Hz, 60+FPS
                        8192: 5.625071493709246, //60Hz, 55FPS
                        16384: 12.063399873076621, //60Hz, 30FPS
                        32768: 25.753349323121988,  //60Hz, 21FPS
                    }
                }

                if (!sum_map[sampleRate]) {
                    return canvas.width; //Then log_sumWidth() will show the the captured width
                } else {
                    let w = sum_map[sampleRate][analyserNode.fftSize];
                    return w ? w : canvas.width;
                }
            };
            const min_octave = Math.floor(Math.log(audible_range[0] / spectrum_base) / Math.log(2)); // -5
            const octave_range = Math.floor(Math.log(audible_range[1] / spectrum_base) / Math.log(2)) - Math.floor(Math.log(audible_range[0] / spectrum_base) / Math.log(2)); //9.965784

            const led_pow = function (rms, l_amp) {
                //rms: Frame's RMS from time domain
                //l_amp: Frame's lowest ampitude from frequency domain. From FFT.
                //Although from 2 distinct source, result should be in range of [0,1] only.
                //As it should be in relational logarithmic scale.
                //However why l_amp goes that value and what is the corrosponding Decibel is yet to known.

                const min = Math.log(-l_amp * analyserNode.fftSize);
                //console.log([l_amp,  analyserNode.fftSize, min, Math.log(rms)]);
                return (Math.log(rms) + min) / min;
            }

            const amp_ledpw = function (rgb, a) {
                return rgb;
            }

            const TWOPI = Math.PI * 2;
            const nuttall = function (i, N) {
                var a0 = 0.355768,
                    a1 = 0.487396,
                    a2 = 0.144232,
                    a3 = 0.012604,
                    f = TWOPI * i / (N - 1)

                return a0 - a1 * Math.cos(f) + a2 * Math.cos(2 * f) - a3 * Math.cos(3 * f)
            }

            //Draw spectrum
            //const barWidth = (canvas.width / bufferLength); // * 2.5;
            const actual_freq = (i) => {
                return sampleRate * (i + 1) / analyserNode.fftSize;
            }

            const barWidth = function (i) {

                let width_multuply = canvas.width / sum_width();
                //let width_multuply = ((canvas.width - bufferLength) / sum_width);
                //width_multuply *
                return width_multuply * Math.pow(2, - ((Math.log(actual_freq(i) / spectrum_base)) / Math.log(2) - min_octave));
                //return Math.pow(1.0035, bufferLength - i);
                //return (canvas.width / bufferLength);
            }

            const log_sumWidth = () => {
                let test_arr = [];
                for (var i = 0; i < analyserNode.fftSize; i++) { test_arr.push(barWidth(i)); }
                //console.log(min_octave);
                //console.log(test_arr);
                console.log(test_arr.reduce((a, b) => a + b));
            }

            log_sumWidth();


            let keep_drawing = true;
            let g_result = { fps_v: 0, fps_a: 0 };
            let g_interval = null;
            audioEle.onended = () => { keep_drawing = false; };

            //Pretty create conversion. Audible to visible.
            // 20~20000Hz = -5 to 5 octave.
            // 10000 - 40 = 9960
            // 1 / ( 1 / 380 - 1 / 780 ) = 741
            const sound_freq_to_light_wavelength = (s_freq) => {
                //It should able to be infinity.
                const octave = Math.log(s_freq / spectrum_base) / Math.log(2) - min_octave;
                const octave_relative_offset = [-1.2, 0.8]; //[bottom, top]
                const octave_scale = (octave_range - octave_relative_offset[1]) / (octave + octave_relative_offset[0]);
                return 1 / (1 / 780 + 1 / (741 * octave_scale));
            };

            const start_analysis_frame = () => {
                let t_start = new Date();
                //console.log("yo");

                let lowest_vol = 0;
                let base_freq = { i: 0, a: analyserNode.minDecibels };

                for (let i = 0; i < bufferLength; i++) {

                    lowest_vol = lowest_vol < dataArray[i] ? lowest_vol : dataArray[i];
                    base_freq = (dataArray[i] > base_freq.a) ? { i: i, a: dataArray[i] } : base_freq;
                }


                let vol_sum = 0;
                for (let i = 0; i < anotherbufferlength; i++) {
                    vol_sum += Math.pow(AnothrDataArray[i], 2);
                }

                let autocol = autoCorrelate(AnothrDataArray, sampleRate);
                let pitch_fz = autocol.freq;
                let vol_rms = Math.sqrt(vol_sum / anotherbufferlength);


                g_result.base_freq = base_freq.i;
                g_result.pitch_fz = pitch_fz;
                g_result.lowest_vol = lowest_vol;
                //g_result.vol_rms_exp = Math.log(vol_rms); //autocol.vol;
                g_result.led_pow = led_pow(vol_rms, lowest_vol);
                //g_result.vol_exp_rms = g_result.vol_exp_rms >= 0? g_result.vol_exp_rms : 0;
                //console.log({pitch_fz, pitch});
                //if (g_result.led_pow < 0) {console.log(g_result.led_pow);}

                //Draw black background
                const fill_bg_greyscale = Math.floor(g_result.led_pow * 256);

                const freq_color_space = wavelengthToColor(sound_freq_to_light_wavelength(pitch_fz > 0 ? pitch_fz : sampleRate * (base_freq.i + 1) / analyserNode.fftSize));
                //freq_color_space=[rgba,r,g,b,a];

                //canvasCtx.fillStyle = `rgba(${fill_bg_greyscale},${fill_bg_greyscale},${fill_bg_greyscale},1)`;
                //Screen is fine for scalar scale
                sce_r = freq_color_space[1] * freq_color_space[4] * g_result.led_pow * 256;
                sce_g = freq_color_space[2] * freq_color_space[4] * g_result.led_pow * 256;
                sce_b = freq_color_space[3] * freq_color_space[4] * g_result.led_pow * 256;

                //Devices strangely has log scale instead of scalar scale
                led_r = freq_color_space[1] * Math.pow(256, freq_color_space[4] * g_result.led_pow);
                led_g = freq_color_space[2] * Math.pow(256, freq_color_space[4] * g_result.led_pow);
                led_b = freq_color_space[3] * Math.pow(256, freq_color_space[4] * g_result.led_pow);

                let t_end = new Date();
                //console.log(t_end - t_start);
                g_result.t_es = t_end.getTime() - t_start.getTime();
            }

            const draw = () => {
                if (!keep_drawing) { return; }

                //Schedule next redraw
                if (!ui_option.noDrawing) {
                    requestAnimationFrame(draw);
                }


                //dataArray = dataArray.map(i => ( nuttall( i, bufferLength) ) );
                //dataArray = dataArray.map(i => i-1.0);
                //console.log(dataArray[0]);

                if (!socket || !foundWorklet) {
                    //Get spectrum data
                    analyserNode.getFloatFrequencyData(dataArray);
                    analyserNode.getFloatTimeDomainData(AnothrDataArray);
                    start_analysis_frame();
                }


                canvasCtx.fillStyle = `rgba(${sce_r},${sce_g}, ${sce_b}, 1)`;
                canvasCtx.fillRect(0, 0, canvas.width, canvas.height);

                let pitch = g_result.pitch_fz > 0 ? Math.round(g_result.pitch_fz * anotherbufferlength / sampleRate) : -1;

                let posX = 0;
                let posX_add = 0;

                const canvas_inc = 1;
                for (let i = 0; i < bufferLength; i++) {
                    const barHeight = (dataArray[i] + (-analyserNode.minDecibels)) * canvas.height / (-analyserNode.minDecibels); //(dataArray[i] + 140) * 2;
                    const barColor = ((i == g_result.base_freq) << 1) + (i == pitch);

                    const default_barColorSpace = wavelengthToColor(sound_freq_to_light_wavelength(actual_freq(i)));
                    const d_r = default_barColorSpace[1] * default_barColorSpace[4] * g_result.led_pow * 256;
                    const d_g = default_barColorSpace[2] * default_barColorSpace[4] * g_result.led_pow * 256;
                    const d_b = default_barColorSpace[3] * default_barColorSpace[4] * g_result.led_pow * 256;

                    switch (barColor) {
                        case 0: canvasCtx.fillStyle = `rgba(${d_r},${d_g}, ${d_b}, 1)`; break;
                        case 1: canvasCtx.fillStyle = "rgb(255,255,255)"; break;
                        case 2: canvasCtx.fillStyle = "rgb(0,0,0)"; break;
                        case 3: canvasCtx.fillStyle = "rgb(128,128,128)"; break;
                        default: canvasCtx.fillStyle = "rgb(128,128,128)";
                    }

                    //Avoid Sub-pixel rendering (Will improve up to 5 FPS when fftsize is high)
                    posX_add += barWidth(i);
                    if (posX_add >= canvas_inc) {
                        canvasCtx.fillRect(posX, canvas.height - barHeight, barWidth(i) >= canvas_inc ? barWidth(i) : canvas_inc, barHeight);
                        posX_add = 0;
                    }
                    //canvasCtx.fillRect(posX, canvas.height - barHeight, barWidth(i), barHeight);
                    posX += barWidth(i);
                    //canvasCtx.fillRect(posX, canvas.height - barHeight, Math.round(barWidth(i)), barHeight);
                    //posX += Math.round(barWidth(i));

                    if (posX > canvas.width) break;
                }

                g_result.fps_v++;

                if (socket && !foundWorklet) {
                    socket.emit("aura", [led_r, led_g, led_b]);
                    socket.emit("logi", [sce_r, sce_g, sce_b].map(d => Math.round(d / 256 * 100)));
                }

            };

            draw();

            clearInterval(g_interval);
            g_interval = setInterval(() => {
                console.log([g_result.fps_a, g_result.t_es]);
                g_result.last_fps_v = g_result.fps_v;
                g_result.last_fps_a = g_result.fps_a;
                g_result.fps_v = 0;
                g_result.fps_a = 0;
            }, 1000);
        }

        let ui_option = {};

        const main2 = (option) => {

            document.getElementById("init_btn").style.display = "none";

            ui_option = option;

            const alert_missing = (missing) => { alert(missing + " is not supported!"); }
            if (!navigator.mediaDevices) { alert_missing("navigator.mediaDevices"); return; }
            if (!navigator.mediaDevices.enumerateDevices) { alert_missing("enumerateDevices"); return; }
            if (!navigator.mediaDevices.getUserMedia) { alert_missing("getUserMedia"); return; }

            //console.log(navigator.mediaDevices.getSupportedConstraints());

            // List cameras and microphones.
            navigator.mediaDevices.enumerateDevices()
                .then(function (devices) {
                    //console.log(devices);

                    const constraints = { audio: true, video: false };
                    return navigator.mediaDevices.getUserMedia(constraints);
                })
                .then(function (ms) {
                    //ms = MediaStrean
                    const ats = ms.getAudioTracks();
                    //if (ats && ats.length && ats[0].enabled) {
                    //
                    //}

                    //console.log(ats);
                    main(ms)
                    //var audioCtx = new AudioContext();
                    //var source = audioCtx.createMediaStreamSource(stream);
                })
                .catch(console.log);

        }
    </script>
</body>
</html>